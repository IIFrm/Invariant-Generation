%!TEX root = paper.tex

\section{Sampling}
In this step, we sample, either randomly or using tools based on the idea of concolic testing~\cite{}, 
a set $T$ of program states and test the program starting with each program state $s$ in $T$. 
We write $Body^*(s)$ to denote the set of program states which could be reached after executing zero or more iterations of the loop starting from $s$. 
We write $Body^*(T)$ to denote $\{s' | \exists s \in T \cdot s' \in Body^*(s)\}$. 
Furthermore, we write $s \Rightarrow s'$ to denote that starting with a program state $s$ would result in state $s'$ when the loop terminates. 

We categorize program states in $Body^*(T)$ into four sets:
$C_T$ which stands for counter-example trace, 
$P_T$ which stands for traces with positive labels, 
$N_T$ which stands for traces with negative labels 
and $U_T$ which stands for traces with unknown labels.
They can be judged by the following rules: 
\begin{itemize}
    \item Set $C_T$ is $\{s \in Body^*(T) | s \in Pre \land s \Rightarrow s' \land s' \notin Post\}$;
    \item Set $P_T$ is $\{s \in Body^*(T) | s \in Pre \land s \Rightarrow s' \land s' \in Post\}$;
    \item Set $N_T$ is $\{s \in Body^*(T) | s \notin Pre \land s \Rightarrow s' \land s' \notin Post\}$;
    \item Set $U_T$ is $\{s \in Body^*(T) | s \notin Pre \land s \Rightarrow s' \land s' \in Post\}$;
\end{itemize}
We remark that anytime a program state in $C_T$ is identified, a counter-example is found and \textsc{Zilu} reports that verification is failed immediately. 
Otherwise, because $Inv$ must satisfy (1),(2) and (3), we know that $P_T \subseteq Inv$ and $N_T \cap Inv = \emptyset$. 
The program states in $U_T$ may or not may be in $Inv$. 
If we know that a program state $s \in U_T$ is in $Inv$, $Body^*(s) \subseteq Inv$.



Due to the limited set of samples we have (which is often referred to as labeled samples in the machine learning community), 
the classifier obtained above might be far from being correct. 
In fact, without labeled samples which are right on the boundary of the `actual' classifier, 
it is very unlikely that we would find it. 
Intuitively, in order to get the `actual' classifier, we would require samples which would distinguish the actual one from any nearby one. 
This problem has been discussed and addressed in the machine learning community using active learning and selective sampling~\cite{DBLP:conf/icml/SchohnC00}.

\begin{algorithm}[t]
\SetAlgoVlined
\Indm
\KwIn{$F^+$ and $F^-$}
\KwOut{a classifier for $F^+$ and $F^-$}
\Indp
let $old$ be $null$\;
\While{true} {
    let $f = classify(F^+, F^-)$\;
    \If {$f$ is identical to $old$} {
        \Return $f$;
    }
    let $old = f$\;
    let $sam$ be a set of samples computed by selective sampling\;
    test the program and update $F^+$ and $F^-$ accordingly\;
}
\caption{Algorithm $activeLearning$}
\label{alg:active}
\end{algorithm}

The concept of active learning or selective sampling refers to the approaches 
that aim at reducing the labeling effort by selecting only the most informative samples to be labeled. 
SVM selective sampling techniques have been proven effective in achieving a high accuracy 
with fewer examples in many applications~\cite{DBLP:conf/mm/TongC01,DBLP:journals/jmlr/TongK01}. 
The basic idea of selective sampling is that at each round, 
we select the samples that are the closest to the classification boundary so that they are the most difficult to classify and the most informative to label. 
Since an SVM classification function is represented by support vectors which are the samples closest to the boundary, 
this selective sampling effectively learns an accurate function with fewer labeled data~\cite{DBLP:conf/icml/SchohnC00}. 
In our setting, this means that we should sample a program state right by the classifier and test the program 
with that state to label that feature vector so that the classifier would be improved.

Algorithm~\ref{alg:active} presents details on how active learning is implemented in \textsc{Zilu}. 
At line 2, we obtain a classifier based on Algorithm~\ref{classify}. 
We compare the newly obtained classifier with the previous one at line 4, if they are identical, we return the classifier; 
otherwise we apply selective sampling so that we can generate additional labeled samples for improving the classifier. 
In particular, at line 5, we apply standard techniques~\cite{DBLP:conf/icml/SchohnC00} to select the most informative sample. 
Notice that in our setting, the most informative samples are those which are exactly on the lines and therefore can be obtained by solving an equation system. 
At line 8, we test the program with the newly generated samples so as to label them accordingly.

\begin{algorithm}[t]
\SetAlgoVlined
\Indm
\KwIn{$Pre$, $Cond$, $Body$, $Post$}
\KwOut{an invariant which completes the proof or a counterexample}
\Indp
let $T$ be a set of random samples\;
\While{true} {
    test the program for each sample in $T$\;
    \If {a state $s$ in $CT$ is identified} {
        \Return $s$ as a counterexample;
    }
    let $P$, $N$ and $NP$ be the respective sets accordingly\;
    let $Inv_u = activeLearning(P, N \cup NP)$\;
    let $Inv_o = activeLearning(P \cup NP, N)$\;
    let $Inv_s = activeLearning(P, N)$\;
    \For {each $Inv$ in $\{Inv_u, Inv_o, Inv_s\}$} {
        \If {(1) or (2) or (3) is not satisfied} {
            add the counterexample into $T$\;
        }
        \Else {
            \Return $Inv$ as the proof;
        }
    }
}
\caption{Algorithm $overall$}
\label{alg:overall}
\end{algorithm}

\begin{example}
\end{example}

\begin{proposition}
Algorithm $activeLearning$ always eventually terminates. \hfill \qed
\end{proposition}


\begin{example}
\end{example}