%!TEX root = paper.tex

\section{Sampling} % (fold)
\label{sec:sampling}
%Before learning procedure, we need to gather some data from program. 
%So 
In this step, we first sample

%, either randomly or using tools based on the idea of concolic testing~\cite{}, 
a set $S$ of program states in three sampling approaches, random sampling, selective sampling and counter-example sampling, 
according to the learning phases.

%In this step, we sample, either randomly or using tools based on the idea of concolic testing~\cite{}, 
%a set $T$ of program states and test the program starting with each program state $s$ in $T$. 
%We write $Body^*(s)$ to denote the set of program states which could be reached after executing zero or more iterations of the loop starting from $s$. 
%We write $Body^*(T)$ to denote $\{s' | \exists s \in T \cdot s' \in Body^*(s)\}$. 
%Furthermore, we write $s \Rightarrow s'$ to denote that starting with a program state $s$ would result in state $s'$ when the loop terminates. 

%We categorize program states in $Body^*(T)$ into four sets:
%$C_T$ which stands for counter-example trace, 
%$P_T$ which stands for traces with positive labels, 
%$N_T$ which stands for traces with negative labels 
%and $U_T$ which stands for traces with unknown labels.
%They can be judged by the following rules: 
%\begin{itemize}
%    \item Set $C_T$ is $\{s \in Body^*(T) | s \in Pre \land s \Rightarrow s' \land s' \notin Post\}$;
%    \item Set $P_T$ is $\{s \in Body^*(T) | s \in Pre \land s \Rightarrow s' \land s' \in Post\}$;
%    \item Set $N_T$ is $\{s \in Body^*(T) | s \notin Pre \land s \Rightarrow s' \land s' \notin Post\}$;
%    \item Set $U_T$ is $\{s \in Body^*(T) | s \notin Pre \land s \Rightarrow s' \land s' \in Post\}$;
%\end{itemize}
%We remark that anytime a program state in $C_T$ is identified, a counter-example is found and \textsc{Zilu} reports that verification is failed immediately. 
%Otherwise, because $Inv$ must satisfy (1),(2) and (3), we know that $P_T \subseteq Inv$ and $N_T \cap Inv = \emptyset$. 
%The program states in $U_T$ may or not may be in $Inv$. 
%If we know that a program state $s \in U_T$ is in $Inv$, $Body^*(s) \subseteq Inv$.

\subsection{Random Sampling}
Random Sampling is applied all along our learning process.
It is a quite intuitive sampling approach, in which each sample is chosen randomly and entirely by chance, 
such that each sample has the same probability of being chosen at any stage during the sampling process.
At the begging of our framework, we use sampling mechanism completely as we have no idea of sample information then. 
In the subsequent iterations, we also use this sampling method partially to avoid the bias resulted from previous sampling iteration.


\subsection{Selective Sampling}
When we have a guess of loop invariants, we can apply selective sampling approach to find more useful samples.
Actually we apply this sampling method all along the learning procedure except the first iteration.
This will be shown in Section Active Learning.



\subsection{Counter-Example Sampling}
Counter-Example sampling is applied after failure of invariant candidate verification (which is described in details in section 5).
After getting an invariant candidate, we try to check it using concolic testing~\cite{} and constraint solving.
When we fails to validate, the constraint solver could provide us with counter-examples, 
which directly refute our invariant candidate.
And as a result, it is quite useful for the invariant candidate refinement in next learning procedure.



\subsection {Labeling}
With the sample set $S$ from the last step, we test the program starting with each program state $s$ in $S$. 
We write $Body^*(s)$ to denote the set of program states which could be reached after executing zero or more iterations of the loop starting from $s$.
So if there is a trace $Trace\{ s_0, s_1, \ldots, s_n\}$, then $s_i \in Body^*(s_0)\ \forall i \in [0 \ldots n]$.
We write $Body^*(S)$ to denote $\{s' | \exists s \in S \cdot s' \in Body^*(s)\}$. 
Furthermore, we write $s \Rightarrow\Rightarrow s'$ to denote that starting with a program state $s$ would result in state $s'$ when the loop terminates. 

\subsubsection*{Positive State, Negative State \& Implication State}

These three concepts are introduced in \cite{sharma2014invariant}.\
In this paper, we use predicates and sets of states interchangeably.
Let $C$ be a candidate invariant.

From equation (1) we know, for an invariant $Inv$, 
any state that satisfies $Pre$ also satisfies $Inv$. 
We call any state that must be satisfied by an actual invariant a positive state. 


Now consider equation (2).
A pair $(s, t)$ satisfies the property that $s$ satisfies $Cond$ and if the execution of $S$
is started in state $s$ then $S$ can terminate in state $t$. 
Since an actual invariant $Inv$ is inductive, it should satisfy $s \in Inv \Rightarrow t \in {Inv}$. 
Hence, a pair $(s, t)$ satisfying $s \in C \land t \notin C$ proves $C$ is not an invariant. 

Finally, consider equation (3).
The `existence of a state $s \in C \wedge \neg B \wedge \neg Post$ proves $C$ is inadequate to discharge the postcondition. 
We call a state $s$ which satisfies $\neg{B} \land \neg{Post}$ a negative state. 



\subsubsection*{Positive Trace, Negative Trace \& Implication Trace}
In our approach, we assume $\{s_0, s_1, s_2, ..., s_i, ... , s_n\}$ is a chain of states in the target program,
where $s_0$ is the initial state before entering the loop, 
and $s_i$ is a state just after the loop has iterated $i$ times in the program.
We assume $s_n$ satisfies $\neg B$ so it is the state that can jump out the loop body.



For a state chain $\{s_0, s_1, s_2, ..., s_i, ... , s_n\}$, 
if $s_0$ satisfies $Pre$, and $s_n$ satisfies $Post$,
we say this is a positive trace,
Because if state $s_0$ satisfy $Pre$,
$s_0$ is a positive state that must satisfy $Inv$, according to equation 1.
Furthermore, according to equation 2,
all of $\{s_1, s_2, ..., s_i, ... , s_n\}$ are positive states.
So now we can get a positive trace  $\{s_0, s_1, s_2, ..., s_i, ... , s_n\}$.


On the contrary, for a state chain $\{s_0, s_1, s_2, ..., s_i, ... , s_n\}$, 
if $s_0$ satisfies $\neg Pre$, and $s_n$ satisfies $\neg Post$,
we say this is a negative trace, 
which means all the states in this chain should be negative states.  

Actually for an arbitrary trace there are also two other possibilities we have not mentioned yet.
One is a trace begins with a state $s_0$ that satisfies $Pre$ but end with a state $s_n$ that satisfies $\neg Post$,
this is a counterexample to disprove the program.
That means there is something wrong with at least one of precondition, loop condition, loop body or postcondition.
We need to find out what happens and update the program, 
after which we can reapply our approach to learn loop invariants.
The other case is a trace begin with a state $s_0$ that satisfies $\neg Pre$ but end with a state $s_n$ that satisfies $Post$.
Under this condition, we could not justify whether $s_0$ and $s_n$ satisfy invariants or not,
not to mention other states $\{s_1, s_2, ..., s_i, ... , s_{n-1}\}$.
The only thing we can ensure is this is an implication trace.
In total, we can have table.~\ref{LabelingTable}.


We categorize program states in $Body^*(S)$ into four sets:
$C_{S}$ which stands for counter-example trace, 
$P_{S}$ which stands for traces with positive labels, 
$N_{S}$ which stands for traces with negative labels 
and $U_{S}$ which stands for traces with unknown labels.



They can be judged according to Table~\ref{LabelingTable}: 

\begin{table}[htb]
\label{LabelingTable}
\centering
\caption{Trace Labeling Table}
\begin{tabular}[float]{|c|c|c|}
\hline
$Trace\{s_0, s_1, ..., s_n\}$         & $s_n \in Post$                     & $s_n \in \neg Post$\\
\hline
$s_o \in Pre$                 & $Trace \in P_{S}$                & $Trace \in C_{S}$\\
\hline
$s_0 \in \neg Pre$            & $Trace \in U_{S}$         & $Trace \in N_{S}$\\
\hline
\end{tabular}
\end{table}


%\begin{itemize}
%    \item Set $C_{T}$ is $\{s \in Body^*(T) | s \in Pre \land s \Rightarrow s' \land s' \nin Post\}$;
%    \item Set $P_{T}$ is $\{s \in Body^*(T) | s \in Pre \land s \Rightarrow s' \land s' \in Post\}$;
%    \item Set $N_{T}$ is $\{s \in Body^*(T) | s \nin Pre \land s \Rightarrow s' \land s' \nin Post\}$;
%    \item Set $U_{T}$ is $\{s \in Body^*(T) | s \nin Pre \land s \Rightarrow s' \land s' \in Post\}$;
%\end{itemize}
%We remark that anytime a program state in $C_T$ is identified, a counter-example is found and \textsc{Zilu} reports that verification is failed immediately. 
%Otherwise, because $Inv$ must satisfy (1),(2) and (3), we know that $P_T \subseteq Inv$ and $N_T \inter Inv = \emptyset$. 
%The program states in $U_T$ may or not may be in $Inv$. 
%If we know that a program state $s \in U_T$ is in $Inv$, $Body^*(s) \subseteq Inv$.









%\newline
%\normal
Among all these possibilities,
we can get more samples than previous approaches can with executing program just once.
So with the sample information, 
the learner can learn an as good invariant as, if not better than, the previous approaches, 
as it can utilize more information to do invariant learning task.
This also implies our approach can get convergence faster than before.











\begin{example}
\end{example}

\begin{proposition}
Algorithm $activeLearning$ always eventually terminates. \hfill \qed
\end{proposition}


\begin{example}
\end{example}


% section sampling (end)
