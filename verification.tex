%!TEX root = paper.tex

\section{Verification} % (fold)
\label{sec:verification}

In this step, having a learned predicate $\mathcal{C}$, we verify whether it is a valid loop invariant by
checking the satisfiability of constraints (1), (2) and (3) using tools from symbolic execution and constraint solving community.
%In addition, we separated this part as a standalone tools for loop invariant verification.

In implementation, to verify constraint (1) and (3), 
$\textsc{Zilu}$ submits constraints $$\{Pre \Rightarrow \mathcal{C}\}$$ and $$\{\neg {Cond} \wedge \mathcal{C} \Rightarrow Post\}$$ to Z3 solver for checking satisfiability.
For example, if we get a predicate $\mathcal{C} = \{199-2*x+2*y>=0\}$
for the loop example in the introduction part, 
we submit 
$$\{(x<y) \Rightarrow (199-2*x+2*y>=0)\}$$
to check constraint (1), 
and 
$$\{\neg(x<y) \wedge (199-2*x+2*y>=0) \Rightarrow ((x >= y \wedge x <= y + 99))\}$$
to check constraint (3).

For checking constraint (2), it might be a bit of complicated due to $Body$'s complexity.
That is why $\textsc{Zilu}$ uses KLEE as a symbolic execution tool to get path condition.
%and Z3 solver as a representative to verify the learned predicate.

%\subsection{Program Recoding}
%$\textsc{Zilu}$ first separates the given loop program with the learned predicate into three loop-free programs,
%which corresponds to constraints (1), (2) and (3).




\subsection{KLEE}
General speaking, KLEE is a symbolic virtual machine built on top of the LLVM compiler infrastructure
that can enumerate all the possible paths based on target configuration on each of them to get all the path conditions.
But in our setting, we are only interested in specific paths which can lead to assertion failure in the target program. 
So we have modified KLEE source code to satisfy our demands, which can emit path conditions at given program location.

\subsection{Z3 Solver}
Z3 is a high-performance theorem prover being developed at Microsoft Research, which is sound and complete.
After compiling three separated programs, we apply our KLEE to get the path constraints and then submit to Z3 solver for solving.

\subsection{Example}
First we separate the given loop program with the leaned predicate into three loop-free programs,
which corresponds to constraints (1), (2) and (3). 

Then we can use symbolic execution to get path conditions and apply constraint solver to do solving.
If all of them are satisfied, we successfully get a valid invariant and also verify the program. 
Otherwise, if any of them is violated, the counterexample obtained is added to the set of sample $X$, (named as counter-example sampling in section 3)
which is then tested, categorized, used for active learning accordingly.




 
The overall algorithm is presented in Figure~\ref{alg:overall}.
\begin{algorithm}[t]
\SetAlgoVlined
\Indm
\KwIn{$Pre$, $Cond$, $Body$, $Post$}
\KwOut{an invariant which completes the proof or a counterexample}
\Indp
let $S$ be a set of random samples\;
\While{true} {
    test the program for each sample in $S$\;
    \If {a state $s$ in $C$ is identified} {
        \Return $s$ as a counterexample;
    }
    let $P$, $N$ and $U$ be the respective sets accordingly\;
    %let $Inv_u = activeLearning(P, N \cup NP)$\;
    %let $Inv_o = activeLearning(P \cup NP, N)$\;
    let $Inv$ = ClassificationAlgorithm($P$, $N$)\;
    \If {$Inv$ not converged} {
        add selectiveSampling($Inv$) into $S$\;
        continue\;
    }
    %\For {each $Inv$ in $\{Inv_u, Inv_o, Inv_s\}$} {
    Divide the loop program into three based on (1)(2)(3)\;
    Run symbolic execution on each of them to get path constraints $PCs$\;
    \For {each $pc$ in $PCs$} {
        \If { $pc$ is not satisfied} {
            add the counterexample into $S$\;
            continue\;
        }
    }
        %\Else {
    \Return $Inv$ as the proof;
        %}
    
}
\caption{Algorithm $overall$}
\label{alg:overall}
\end{algorithm}


%We remark that we learn three classifiers as candidates for the loop invariant: $U$, $OU$, $O$ such that
%\begin{itemize}
%\item $U$ classifies states in $P$ and those in $N \cup NP$.
%\item $O$ classifies states in $N$ and those in $P \cup NP$.
%\item $OU$ classifies states in $P$ and $N$;
%\end{itemize}
%Intuitively, $U$ would be an under-approximation of $Inv$ (by assuming states in $NP$ does not satisfy $Inv$); 
%$O$ would be an over-approximation of $Inv$ (by assuming states in $NP$ does satisfy $Inv$); 
%and $OU$ would be an safe-approximation of $Inv$ (by using states which we are certain whether they are in $Inv$ or not).
\begin{example}
\end{example}


\begin{theorem}
Algorithm $overall$ always eventually terminates and it is correct. \hfill \qed
\end{theorem}


% section verification (end)