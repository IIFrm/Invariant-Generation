%!TEX root = paper.tex

\section{Verification}
Given a learned predicate $Inv$, we verify whether constraint (1), (2) and (3) are satisfied using symbolic execution. 
If all of them are satisfied, we successfully verify the program. 
Otherwise, if any of them is violated, the counterexample obtained is added to the set of sample $X$,
 which is then tested, categorized, used for active learning accordingly. 
 The overall algorithm is presented in Figure~\ref{alg:overall}.

We remark that we learn three classifiers as candidates for the loop invariant: $U$, $OU$, $O$ such that
\begin{itemize}
\item $U$ classifies states in $P$ and those in $N \cup NP$.
\item $O$ classifies states in $N$ and those in $P \cup NP$.
\item $OU$ classifies states in $P$ and $N$;
\end{itemize}
Intuitively, $U$ would be an under-approximation of $Inv$ (by assuming states in $NP$ does not satisfy $Inv$); 
$O$ would be an over-approximation of $Inv$ (by assuming states in $NP$ does satisfy $Inv$); 
and $OU$ would be an safe-approximation of $Inv$ (by using states which we are certain whether they are in $Inv$ or not).
\begin{example}
\end{example}


\begin{theorem}
Algorithm $overall$ always eventually terminates and it is correct. \hfill \qed
\end{theorem}
